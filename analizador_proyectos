import os
import re
import json
import pdfplumber  # <-- CAMBIO: Usamos pdfplumber en lugar de fitz (PyMuPDF)
import nltk      # <-- NUEVO: A√±adimos la biblioteca de Procesamiento de Lenguaje Natural
from datetime import datetime
from uuid import uuid4

# ------------------ CONFIGURACI√ìN INICIAL ------------------
PDF_FOLDER = "pdfs"  # Carpeta donde est√°n los PDF
RESULT_FOLDER = "resultados"
os.makedirs(RESULT_FOLDER, exist_ok=True)

# Descargar el modelo 'punkt' de NLTK para separar frases de forma inteligente.
# Solo se descarga una vez si no est√° presente.
try:
    nltk.data.find('tokenizers/punkt')
except nltk.downloader.DownloadError:
    print("INFO: Descargando el modelo 'punkt' de NLTK para an√°lisis de frases...")
    nltk.download('punkt')
    print("INFO: Descarga completada.")

# ------------------ FUNCIONES MEJORADAS ------------------

def limpiar_frase(texto: str) -> str:
    """Limpia una √∫nica frase eliminando saltos de l√≠nea y espacios extra."""
    texto = texto.replace("\n", " ").replace("\t", " ")
    texto = re.sub(r"\s+", " ", texto).strip()
    return texto

def extraer_texto_pdf_con_plumber(pdf_path: str) -> str:
    """
    NUEVA FUNCI√ìN DE EXTRACCI√ìN:
    Usa pdfplumber para extraer texto de un PDF, respetando tablas y columnas.
    """
    texto_completo = ""
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page in pdf.pages:
                # .extract_text() de pdfplumber es excelente para mantener el orden de lectura
                texto_pagina = page.extract_text(x_tolerance=2, layout=True)
                if texto_pagina:
                    texto_completo += texto_pagina + "\n"
        return texto_completo
    except Exception as e:
        print(f"‚ùå Error procesando {pdf_path} con pdfplumber: {e}")
        return ""

def extraer_frases_unicas_con_nltk(texto: str):
    """
    NUEVA FUNCI√ìN DE SEPARACI√ìN DE FRASES:
    Usa NLTK para una separaci√≥n de frases m√°s precisa y luego limpia y filtra.
    """
    # NLTK es m√°s inteligente que un simple split, entiende abreviaturas como "Mr." o "e.g."
    # Usamos 'english' porque el documento de ejemplo est√° en ingl√©s. Cambiar si es necesario.
    frases = nltk.sent_tokenize(texto, language='english')
    
    # Aplicamos la limpieza a cada frase y nos quedamos con las √∫nicas y de longitud adecuada
    frases_limpias = set()
    for frase in frases:
        frase_limpia = limpiar_frase(frase)
        if len(frase_limpia) > 20: # Mantenemos tu filtro de m√°s de 20 caracteres
            frases_limpias.add(frase_limpia)
            
    return list(frases_limpias)

def procesar_todos_los_pdfs():
    """
    FUNCI√ìN PRINCIPAL (MODIFICADA LIGERAMENTE):
    Usa las nuevas funciones de extracci√≥n y separaci√≥n.
    """
    resultados = []
    lista_pdfs = [f for f in os.listdir(PDF_FOLDER) if f.lower().endswith(".pdf")]
    
    if not lista_pdfs:
        print(f"AVISO: No se encontraron archivos PDF en la carpeta '{PDF_FOLDER}'.")
        return
        
    print(f"Encontrados {len(lista_pdfs)} PDF(s). Iniciando procesamiento...")
    
    for archivo in lista_pdfs:
        ruta = os.path.join(PDF_FOLDER, archivo)
        
        # 1. Extraer texto con el m√©todo mejorado de pdfplumber
        texto = extraer_texto_pdf_con_plumber(ruta)
        
        if not texto:
            print(f"‚ö†Ô∏è  No se pudo extraer texto de {archivo}.")
            continue
            
        # 2. Separar en frases con el m√©todo mejorado de NLTK
        frases = extraer_frases_unicas_con_nltk(texto)
        
        resultados.append({
            "archivo": archivo,
            "id": str(uuid4()),
            "procesado_en": datetime.now().isoformat(),
            "num_frases": len(frases),
            "frases": frases
        })
        print(f"‚úÖ {archivo} ‚Üí {len(frases)} frases √∫nicas extra√≠das.")

    salida = os.path.join(RESULT_FOLDER, "frases_extraidas_mejorado.json")
    with open(salida, "w", encoding="utf-8") as f:
        json.dump(resultados, f, indent=2, ensure_ascii=False)
    print(f"\nüìÑ ¬°Proceso completado! Frases guardadas en: {salida}")

# ------------------ EJECUCI√ìN ------------------
if __name__ == "__main__":
    procesar_todos_los_pdfs()
